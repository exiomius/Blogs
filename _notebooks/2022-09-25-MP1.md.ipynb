{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a116df26",
   "metadata": {},
   "source": [
    "# Masters Project First Post\n",
    "\n",
    "This is the start of a series of posts about my Masters project with the Physics Department at Durham University."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a246d10b",
   "metadata": {},
   "source": [
    "To being with, here is the official project description as presented by the department:\n",
    "\n",
    "# Title: Data science for biodiversity loss\n",
    "\n",
    "Supervisor: Prof Charles Adams.\n",
    "Second Supervisor: Dr Robert Potvliege.\n",
    "Category: General.\n",
    "Type: Computation/Data Analysis/Experiment.\n",
    "\n",
    "Biodiversity loss due to human action is increasingly creating an existential threat to all live on Earth. In order to take appropriate action we need better data. However biodiversity data is both more diverse and more difficult to accumulate than say climate data. In this project, we shall look at data analysis on bird song. Although, under ideal conditions it is possible to identify different species [1-3]. In a noisy environment, which is more typical, this becomes more challenging. One approach that we shall pursue is to construct time frequency pattern and then use pattern recognition technique to identify particular events [4].\n",
    "\n",
    "[1]  [scikit‐maad An open‐source and modular toolbox for quantitative soundscape analysis in Python, Ulloa et al, Meth. in Ecology and Evolution, 12, 2334 2021](https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/2041-210X.13711)\n",
    "\n",
    "[2]  [Multifractal analysis of birdsong and its correlation structure, R Bishal, GB Mindlin, and N Gupte Phys. Rev. E 105, 014118 2022](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.105.014118)\n",
    "\n",
    "[3]  [Large-scale analysis of frequency modulation in birdsong data bases, D Stowell, MD Plumbley, Methods Ecol Evol, 5: 901 (2014)](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12223)\n",
    "\n",
    "[4]  [New aspects in birdsong recognition utilizing the gabor transform, S HEUER , P TAFO, H HOLZMANN, S DAHLKE, Proc. of the 23rd Int. Congress on Acousitics, Aachen, September 9-13, 2019.](https://www.mathematik.uni-marburg.de/~heuersv/paper/birdsong_recognition_utilizing_gabor_transform.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bebf3b",
   "metadata": {},
   "source": [
    "# Aim\n",
    "In essence, the (first) aim of this project is to pick apart bird song from a noisy sound recording and identify birds from it. \n",
    "\n",
    "In the future other aims may emerge, such as trying to understand the meaning behind birdsong rather than classify their singers. Perhaps even trying to generate birdsong may be an interesting idea to yield some insights. It would be fascinating seeing if/how birds would respond to generated birdsong. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0c22e",
   "metadata": {},
   "source": [
    "# Approaches\n",
    "The four above referenced papers are probably the best place to start when looking for initial approaches. While I am comfortable with both Physics and Programming, my preference in comfortability and in interest does lean towards the latter, especially when Machine Learning is involved. Having said that, the first, third and fourth reference all are ML based to a degree. \n",
    "\n",
    "I don't yet have the prerequisite knowledge to understand at a glance the abstracts of the second and third references. \n",
    "\n",
    "The first however is an open-source Python module called scikit-maad, which is instantly recognisable by my familiarity with other popular scikit modules. Furthermore, I feel warmly welcomed by the described online documentation and practical examples around it. Lastly, the module highlights its ability to easily integrate Machine Learning Python packages. \n",
    "\n",
    "The fourth reference details that current approaches convert audio recordings into spectrograms using the Gabor transform, then enter them as images to a CNN for classification. This is a really intuitive ML approach, and one I might try and implement. The paper then details that most approaches focus on finding the best CNN hyperparameters for accuracy, so in contrast the authors attempt to evaluate the parameters for the Gabor transform itself.\n",
    "\n",
    "All in all, I think my first priority is to investigate and implement the first and fourth references. It's not ideal not being able to easily understand the other papers, but my reasoning is that having gone through the more understandable references first would yield prerequisite knowledge to go back and understand the others.\n",
    "\n",
    "Coincidentally, I was talking briefly with my older brother about the project and he commented that the problem is awfully similar to other audio separation problems. Separating out bird song from a noisy forest environment and then identifying them, is similar to separating out instrument sounds from a regular song and identifying them. We both actually have a mutual friend who did his Masters project in the latter. Spotify also appears to have its own development going on for this problem. Looking through how similar these two problems are might prove very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a988ff3",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "Currently I am still doing the first part of the excellent Fast.ai deep learning online course. As this project is in joint collaboration with the biology department, we are having a full team meeting in a few weeks. \n",
    "\n",
    "Firstly I will finish off the first part of Fast.ai since it really is interesting and useful for both this project and my future prospects. \n",
    "\n",
    "What to do next however is a bit less obvious. To work on the aforementioned project references or to continue with the new Fast.ai course:\n",
    "\n",
    "Fast.ai is releasing the second half of their 2022 course starting this October. From a personal perspective it is really attractive to focus on it because it aligns with my graduate and personal interests. From a project perspective it is attractive to focus on it because of Fast.ai's fixation on updating and teaching state-of-the-art techniques. The course would provide me with excellently taught tools to tackle the project with. \n",
    "\n",
    "However, the course would likely be time consuming: it will contain eight weekly lessons, each with a double lecture, programming notebook(s), a textbook chapter, and a question sheet. Having said that, some lessons in part 1 actually didn't take me an enormous amount of time to complete. Others, like lesson 2, took a very long time. Since part 2 is advanced, I'd imagine it would be considerably harder. \n",
    "\n",
    "There is a registration deadline (7th October) and payment (175 Australian dollars, about £102). Although, come early 2023, the course will become available online for free. \n",
    "\n",
    "Between finishing my Laidlaw Internship, doing my part-time job at the university, studying for the other modules of my degree, and of course participating in university life, I have to be efficient with the time I spend for my Masters project. \n",
    "\n",
    "My current plan is to:\n",
    "Finish Fast.ai part 1. \n",
    "I will prioritise going through scikit-maad. I will however, still register and purchase Fast.ai part 2. If time allows (within my free time and during holidays), I will go through the course.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
