<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Masters Project 18/10/2022 | RvCode</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Masters Project 18/10/2022" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My personal website." />
<meta property="og:description" content="My personal website." />
<link rel="canonical" href="https://exiomius.github.io/Blogs/mp/2022/10/13/MP4.html" />
<meta property="og:url" content="https://exiomius.github.io/Blogs/mp/2022/10/13/MP4.html" />
<meta property="og:site_name" content="RvCode" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-13T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Masters Project 18/10/2022" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-13T00:00:00-05:00","datePublished":"2022-10-13T00:00:00-05:00","description":"My personal website.","headline":"Masters Project 18/10/2022","mainEntityOfPage":{"@type":"WebPage","@id":"https://exiomius.github.io/Blogs/mp/2022/10/13/MP4.html"},"url":"https://exiomius.github.io/Blogs/mp/2022/10/13/MP4.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Blogs/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://exiomius.github.io/Blogs/feed.xml" title="RvCode" /><link rel="shortcut icon" type="image/x-icon" href="/Blogs/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Blogs/">RvCode</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Blogs/about/">About Me</a><a class="page-link" href="/Blogs/search/">Search</a><a class="page-link" href="/Blogs/categories/">Projects</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Masters Project 18/10/2022</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-10-13T00:00:00-05:00" itemprop="datePublished">
        Oct 13, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      11 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Blogs/categories/#MP">MP</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/exiomius/Blogs/tree/master/_notebooks/2022-10-13-MP4.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Blogs/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/exiomius/Blogs/master?filepath=_notebooks%2F2022-10-13-MP4.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blogs/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/exiomius/Blogs/blob/master/_notebooks/2022-10-13-MP4.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Blogs/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fexiomius%2FBlogs%2Fblob%2Fmaster%2F_notebooks%2F2022-10-13-MP4.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/Blogs/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-10-13-MP4.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>(This post is in progress)</p>
<h1 id="Meeting:">Meeting:<a class="anchor-link" href="#Meeting:"> </a></h1><p>During the meeting we discussed:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Problem-definition-update">Problem definition update<a class="anchor-link" href="#Problem-definition-update"> </a></h1><p>From now on, I will refer to the problem of trying to identify birds in a noisy environment as 'the cocktail problem', as in at a cocktail party where many people are speaking and where the environment is noisy, it is hard to tell who is speaking. <br /></p>
<p>A soundscape is going to be defined as an audio file that contains various birdsong in a noisy environment. We are trying to classify birds from a soundscape.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Work-to-do:">Work to do:<a class="anchor-link" href="#Work-to-do:"> </a></h1><p>I've been thinking about all the things I need to do and learn for this project. Here is an overview of them. It's honestly a lot of work, and hard to tell how much time each will take until I make more progress. It might take the whole of first term to get a handle on this.</p>
<h2 id="1.-Machine-Learning-Skills">1. Machine Learning Skills<a class="anchor-link" href="#1.-Machine-Learning-Skills"> </a></h2><p>Using frameworks like fast.ai and transformers isn't as simple as just using their predefined functions and models to do everything. Learning how to find the best hyperparameters, and good validation sets, among many other things, takes a combination of theory and practice to gain intuition. Jeremy from fast.ai said there is no substitute for practice, and provides a lot of guidance on how to do so.</p>
<h2 id="2.-Machine-Learning-Theory">2. Machine Learning Theory<a class="anchor-link" href="#2.-Machine-Learning-Theory"> </a></h2><p>As well as using frameworks and models, you have to spend time learning the theory behind how they work. For instance, how the components in a CNN work the way they do.</p>
<h2 id="3.-Framework-Skills">3. Framework Skills<a class="anchor-link" href="#3.-Framework-Skills"> </a></h2><p>Understanding the theory, and then having novel ideas to approach the cocktail problem, I need to then implement these ideas by knowing how to create the new code to do so. <br />
This involves learning how to edit frameworks and create your own, covered in fast.ai part 2. <br /></p>
<p>There's also learning about <a href="https://nbdev.fast.ai/">https://nbdev.fast.ai/</a> to create frameworks and their documentation.</p>
<h2 id="4.-Data-handling/preprocessing/Physics">4. Data handling/preprocessing/Physics<a class="anchor-link" href="#4.-Data-handling/preprocessing/Physics"> </a></h2><p>Learning how to store data, access it, transform it into the right size and format, edit it, add noise to it, interpret it (bird domain information) etc. 
<br />
There could be much work to be done on transforming the audio data. Fourier and Gabor transformers etc. I found a YouTube playlist of guides on this at <a href="https://www.youtube.com/watch?v=RMfeYitdO-c">https://www.youtube.com/watch?v=RMfeYitdO-c</a>. The fourth initial project reference, "New aspects in birdsong recognition utilizing the gabor transform", focuses on the gabor transform and likely much Physics too.</p>
<h2 id="5.-Custom-metrics,-creation,-and-evaluation-for-models">5. Custom metrics, creation, and evaluation for models<a class="anchor-link" href="#5.-Custom-metrics,-creation,-and-evaluation-for-models"> </a></h2><p>The biology department have their own interests and goals of what they want from a model. I would need to talk in detail with them about their priorities, e.g. preferences in confusion matrix metrics, in bird species etc. They might want a model to work with data over a few years to spot trends too.</p>
<h2 id="6.-Machine-learning-explainability-and-communication">6. Machine learning explainability and communication<a class="anchor-link" href="#6.-Machine-learning-explainability-and-communication"> </a></h2><p>Learning how to implement and create methods and visualisations to communicate why the models are predicting as they do. This is especially important for marking in the final report.</p>
<h2 id="7.-Machine-learning-maths.">7. Machine learning maths.<a class="anchor-link" href="#7.-Machine-learning-maths."> </a></h2><p>To read and implement the latest machine learning papers, some mathematical knowledge is needed. I am contemplating doing yet another free fast.ai course, Computational Linear Algebra, explained here <a href="https://www.fast.ai/posts/2017-07-17-num-lin-alg.html">https://www.fast.ai/posts/2017-07-17-num-lin-alg.html</a>, to help with the maths side of things. <br /></p>
<p>Alternatively or in addition, the book Deep Learning by Ian Goodfellow provides a mathematical backing and Jeremy recommended reading the first 6 chapters of it to help with understanding and implementing maths in papers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Work-done">Work done<a class="anchor-link" href="#Work-done"> </a></h1><h3 id="Practiced-Transformers">Practiced Transformers<a class="anchor-link" href="#Practiced-Transformers"> </a></h3><p>A list of transformer tasks is at <a href="https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb">https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/task_summary.ipynb</a> which is quite useful. <br /></p>
<p>In particular for audio classification it details the process: <br />
"</p>
<ol>
<li>Instantiate a feature extractor and a model from the checkpoint name.</li>
<li>Process the audio signal to be classified with a feature extractor.</li>
<li>Pass the input through the model and take the argmax to retrieve the most likely class.</li>
<li>Convert the class id to a class name with id2label to return an interpretable result.
"</li>
</ol>
<p>I went through the HuggingFace transformers documentation and did some of the notebooks to understand them.</p>
<ul>
<li><a href="https://www.kaggle.com/adnanjinnah/audio-classification-hf-1/">https://www.kaggle.com/adnanjinnah/audio-classification-hf-1/</a></li>
<li><a href="https://www.kaggle.com/adnanjinnah/audio-classification-hf-2/">https://www.kaggle.com/adnanjinnah/audio-classification-hf-2/</a></li>
<li><a href="https://www.kaggle.com/adnanjinnah/audio-classification-hf-3/">https://www.kaggle.com/adnanjinnah/audio-classification-hf-3/</a>
and they covered the 4 step process detailed above.</li>
</ul>
<h3 id="Practiced-Trying-to-attempt-BirdCLEF-2022">Practiced Trying to attempt BirdCLEF 2022<a class="anchor-link" href="#Practiced-Trying-to-attempt-BirdCLEF-2022"> </a></h3><p>It's well worth practicing attempts for a competition with the goal exactly as my own.
After trying fast.ai's audio module last week, and thinking it is outdated (the GitHub repo hasn't been updated in roughly 6 months), I decided to use HuggingFace instead. This is mainly due to Jeremy recommending it as an up to date framework, but also because it is used in fast.ai part 2.</p>
<p>With that in mind, I attempted it at <a href="https://www.kaggle.com/adnanjinnah/birdclef-first-attempt/">https://www.kaggle.com/adnanjinnah/birdclef-first-attempt/</a>.
This attempt was writhe with problems. While it was my first time using HuggingFace audio, the number of problems I encountered and issues involved were too much. I did not manage to get any model to work. I spent the entire time just trying to get the data loaded properly for usage.</p>
<p>To summarise:</p>
<ul>
<li>HuggingFace's load_model has several different methods to load audio. They all require the data to be formatted in a particular way. I tried all them with no success.</li>
<li>Kaggle's competition dataset is set to read only for some reason. This makes it so I cannot directly just edit the files to get them right.</li>
<li>I tired simply downloading the dataset and reuploading it to Kaggle but A. this is inefficient and B. won't work for the unseen test data.</li>
<li>I tried copying over the dataset from the read-only input folder to the editable output folder, but this is also inefficient and even so:</li>
<li>I couldn't load the copied data using load_dataset's audiofolder function. I'm not sure why. I have it formatted in the exact way the documentation shows. The issue may be I need to upload the dataset to HuggingFace's website first, but this has the same issues as the first attempt.</li>
<li>A way to get around having to copy the data, with is also inefficient but would atleast work with the unseen test data is to tell load_dataset the URLs of the audio files. This didn't work either, because some of the URLs don't work in the instant load_dataset wants to access them. I couldn't find a way to tell load_dataset to ignore or look later at these URLs.</li>
<li>I tried using a different method of load_dataset, this one however seems to require the main .csv file to contain the audio files in array format. Because the .csv file contains a path to the audio files instead of their content, I tried using another module, librosa, to create a column in the .csv file containing the audio. This didn't work, because of an excess memory error. And also, this is very inefficient. </li>
</ul>
<p>After extensively trying all methods I could find in the documentation with little success, this entire process took around 10 hours. I found tutorials to help with no luck. For now, I've given up on trying to get it to work myself. I need to find some resource online or in person to help. In hindsight, I probably should have done this earlier.</p>
<p>On the bright side, atleast I learn't a few things from the struggle:</p>
<ul>
<li>First, how transformers requires a dataset to be formatted in a specific way, and that HuggingFace has a website dedicated to storing datasets in an already formatted way.</li>
<li>Experience in reading through documentation and troubleshooting.</li>
<li>The fact that sometimes URLs don't work, and that last week's code had a solution, but I couldn't implement it into HuggingFace's load_model.</li>
<li>That different loading methods require paths to audio files or them on the .csv file.</li>
<li>That audio files are stored as a file such as .ogg or as an array.</li>
<li>How librosa is a module to convert audio files into audio files into said arrays.</li>
<li>That memory errors will occur from trying to do too much at once. I could get my last method to work if I figured out a way to split up the data, but regardless this approach is inefficient considering we already have the files so it's better to find a different method.</li>
<li>How to use os to copy files and folders over, or search and retrieve their file paths.</li>
<li>The fact that, for some datasets like BirdCLEF, there is a metadata.csv file with a column for the paths of the audio files.</li>
<li>That for advanced dataset formatting, for HuggingFace, you can create a .py script to do things exactly as you want.</li>
</ul>
<h3 id="Finished-fast.ai-lesson-9:">Finished fast.ai lesson 9:<a class="anchor-link" href="#Finished-fast.ai-lesson-9:"> </a></h3><p>This lesson was the first of fast.ai part 2 and a very well taught one.
In it, Jeremy described conceptually how stable diffusion, an crazy new image generation model, works.
Due to it's difficulty, the lesson took me a full day to complete, but it was well worth it. The ideas and skills I'm being introduced to and learning will prove really helpful for the project going forwards. 
Next week, the lesson will focus on programming stable diffusion from scratch, and building on that, how to programme your own custom Python machine learning libraries. This is vital because it would allow me not just to copy other people's code to solve the cocktail problem, but implement my own ideas and test things, perhaps even at a research level.</p>
<p>My post for lesson 9 can be found at: <strong>Need to fix FastPages</strong></p>
<h3 id="Finished-CLA-lesson-1:">Finished CLA lesson 1:<a class="anchor-link" href="#Finished-CLA-lesson-1:"> </a></h3><p>Computational Linear Algebra is a fast.ai course covering linear algebra to be centered around practical applications and algorithms. <br />
More info and lesson 1 blog can be found here: <strong>Need to fix FastPages</strong></p>
<h3 id="Useful-Datasets-Found">Useful Datasets Found<a class="anchor-link" href="#Useful-Datasets-Found"> </a></h3><ul>
<li>BirdCLEF 2022 uses data from xeno-carto, implying that last week's approach to downloading them is a good idea.</li>
<li>I found ESC-50, a dataset of labeled environmental audio recordings at <a href="https://dagshub.com/kinkusuma/esc50-dataset">https://dagshub.com/kinkusuma/esc50-dataset</a>, also at <a href="https://huggingface.co/datasets/ashraq/esc50">https://huggingface.co/datasets/ashraq/esc50</a>. These include sounds like rain, sea waves, animals.</li>
<li>I found that Machine Listening Lab at Queen Mary's University run a birdsong competition and have many datasets that I could possibly use at <a href="http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/">http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/</a>.</li>
</ul>
<h3 id="Useful-Research-Tools">Useful Research Tools<a class="anchor-link" href="#Useful-Research-Tools"> </a></h3><ul>
<li>Scholarcy summarises research articles.</li>
<li><a href="https://inciteful.xyz/">https://inciteful.xyz/</a> is good for finding papers.</li>
<li>I was told that Prostudy is useful for keeping resources stored for a dissertation. </li>
</ul>
<h3 id="A-Similar-Thesis">A Similar Thesis<a class="anchor-link" href="#A-Similar-Thesis"> </a></h3><p>My friend's friend wrote a thesis similar in aim to mine last year. <br /></p>
<p>Title: Using mel-frequency cepstral coefficients and principal components analysis to classify bird vocalisations based on citizen science recordings. <br />
Student Name: Alex Dyfrig Swainston. <br /></p>
<p>I messaged Alex and got a copy, and he said he's happy to help if I have any questions.</p>
<h3 id="New-Ideas:">New Ideas:<a class="anchor-link" href="#New-Ideas:"> </a></h3><p>Here are a few new ideas I had about tackling the cocktail problem.</p>
<p>A big issue is the lack of properly labeled data for soundscapes.
The biology department painstakingly handlabeled some soundscapes, but it is a difficult and time consuming task that even great ecologists struggle with. What if there was a way to create our own soundscapes that are already labeled?
For instance, we have plenty of data from xeno-canto of individual bird songs with varying amounts of noise. What if I also found some audio files of forest environments, and I created a model to combine xeno-canto bird songs with these to imitate a real soundscape? This way, I could create an endless amount of soundscapes to train on, and the birds within them would be labeled!</p>
<p>To create a soundscape:</p>
<ul>
<li>I could download bird song(s),</li>
<li>Cut out various parts of them, e.g. if it's 3 minutes long, I cut out random intervals of 20-30 seconds to imitate the bird moving or other sounds overpowering their song,</li>
<li>Randomly vary how loud the bird songs are,</li>
<li>Add in enviromental sounds like a forest soundscape (but being careful there are no birds present!),</li>
<li>Use a noise function, (which is used in stable diffusion), to randomly add noise. Alternatively, find a way to make a model that can generate real noise that is recorded by microphones and use that.</li>
</ul>
<p>I could put multiple birdsongs in the same artifical soundscape, and even make them overlap, but I also need to be careful that perhaps I should make the birds singing be realistically in the same environment. I mean I shouldn't put two birds together that geographically would never meet, or two birds that never sing at the same time of day, or in general enviromental sounds that don't match the birds present.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/Blogs/mp/2022/10/13/MP4.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Blogs/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Blogs/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Blogs/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My personal website.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/Blogs/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/Blogs/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
